import streamlit as st
import os
import streamlit as st
import requests

# GitHub ã‚·ãƒ¼ã‚¯ãƒ¬ãƒƒãƒˆ or Streamlit secrets ã‹ã‚‰ API ã‚­ãƒ¼ã‚’å–å¾—
OPENAI_API_KEY = st.secrets["OPENAI_API_KEY"]
GROQ_API_KEY = st.secrets["GROQ_API_KEY"]

# ChatGPT & Groq ã® APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ
OPENAI_URL = "https://api.openai.com/v1/chat/completions"
GROQ_URL = "https://api.groq.com/openai/v1/chat/completions"

st.set_page_config(page_title="Chatbot (GPT-3.5-Turbo & Groq)", page_icon="ğŸ¤–",layout="wide")

# ãƒ¢ãƒ‡ãƒ«ã®ä¾¡æ ¼ãƒªã‚¹ãƒˆ
MODEL_PRICES = {
    "input": {
        "gpt-3.5-turbo": 0.5 / 1_000_000,
        "mixtral-8x7b-32768": 3 / 1_000_000
    },
    "output": {
        "gpt-3.5-turbo": 1.5 / 1_000_000,
        "mixtral-8x7b-32768": 15 / 1_000_000
    }
}

# ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®åˆæœŸåŒ–
if "message_history" not in st.session_state:
    st.session_state.message_history = [("system", "ALTAM is a helpful assistant.")]

# ğŸ”¹ **AIã‚¨ãƒ³ã‚¸ãƒ³ã‚’åˆ‡ã‚Šæ›¿ãˆ**
def chat_with_ai(user_input, model_instance, temperature):
    """GPT-3.5-Turbo ã¾ãŸã¯ Groq (Mixtral) ã§å¿œç­”ã‚’ç”Ÿæˆ"""

    if not model_instance:
        return "âš ï¸ ãƒ¢ãƒ‡ãƒ«ãŒæ­£ã—ãé¸æŠã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚"

    # ç›´è¿‘ã®å±¥æ­´ N ä»¶ã®ã¿ã‚’é€ä¿¡
    N = 3  
    messages = [{"role": role, "content": content} for role, content in st.session_state.message_history[-N:]]
    messages.append({"role": "user", "content": user_input})

    payload = {
        "model": model_instance["model_name"],
        "messages": messages,
        "max_tokens": 200,
        "temperature": temperature
    }

    headers = {
        "Authorization": f"Bearer {model_instance['api_key']}",
        "Content-Type": "application/json"
    }

    try:
        response = requests.post(model_instance["api_url"], headers=headers, json=payload)
        response.raise_for_status()  # HTTPã‚¨ãƒ©ãƒ¼ãŒã‚ã‚Œã°ä¾‹å¤–ã‚’ç™ºç”Ÿã•ã›ã‚‹

        ai_response = response.json()["choices"][0]["message"]["content"].strip()

        # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
        st.session_state.message_history.append(("user", user_input))
        st.session_state.message_history.append(("assistant", ai_response))

        return ai_response

    except requests.exceptions.RequestException as e:
        st.error(f"âš ï¸ APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")  # ã‚¨ãƒ©ãƒ¼ã‚’Streamlitã®UIã«è¡¨ç¤º
        return f"âš ï¸ APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}"


# ğŸ”¹ **ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®è¨­å®š**
def init_sidebar():
    st.sidebar.title("ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

    # ğŸ”¹ **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠ**
    page = st.sidebar.selectbox("ğŸ“‚ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’é¸æŠ:", ["Home", "é‡‘èèª¿æŸ»å“¡", "åŒ»è€…", "ãƒ—ãƒ­ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢"])

    # ä¼šè©±å±¥æ­´ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³
    if st.sidebar.button("ğŸ—‘ ä¼šè©±å±¥æ­´ã®ãƒªã‚»ãƒƒãƒˆ"):
        st.session_state.message_history = [("system", "ALTAM is a helpful assistant.")]

    # ãƒ¢ãƒ‡ãƒ«é¸æŠ
    models = ["GPT-3.5-Turbo", "Groq (Mixtral)"]
    model = st.sidebar.radio("ğŸ¤– ãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠ:", models)

    # Temperature ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼
    temperature = st.sidebar.slider("Temperature:", 0.0, 2.0, 0.7, 0.01)

    # ãƒ¢ãƒ‡ãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®è¨­å®š
    model_instance = {
        "GPT-3.5-Turbo": {
            "api_url": OPENAI_URL,
            "api_key": OPENAI_API_KEY,
            "model_name": "gpt-3.5-turbo"
        },
        "Groq (Mixtral)": {
            "api_url": GROQ_URL,
            "api_key": GROQ_API_KEY,
            "model_name": "mixtral-8x7b-32768"
        }
    }.get(model, None)


    return model_instance, page, temperature

# ğŸ”¹ **ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿ã®ãƒ­ãƒ¼ãƒ‰**
def load_project_data(project_name):
    project_data = {
        "é‡‘èèª¿æŸ»å“¡": "ãƒ‡ãƒ¼ã‚¿1: é‡‘èãƒ¬ãƒãƒ¼ãƒˆ",
        "åŒ»è€…": "ãƒ‡ãƒ¼ã‚¿2: åŒ»ç™‚è«–æ–‡",
        "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢": "ãƒ‡ãƒ¼ã‚¿3: Pythonãƒãƒ¥ãƒ¼ãƒˆãƒªã‚¢ãƒ«"
    }
    return project_data.get(project_name, "ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒ•ã‚¡ã‚¤ãƒ«")

# ğŸ”¹ **ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹**
def chat_interface(model_instance, temperature):
    """Streamlit ã®ãƒãƒ£ãƒƒãƒˆUIã‚’æä¾›"""

    st.title("ğŸ’¬ ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ")

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º
    chat_log = ""
    for role, message in st.session_state.message_history:
        if role == "user":
            chat_log += f"ğŸ‘¤ **ãƒ¦ãƒ¼ã‚¶ãƒ¼**: {message}\n\n"
        elif role == "assistant":
            chat_log += f"ğŸ¤– **AI**: {message}\n\n"

    # ãƒãƒ£ãƒƒãƒˆãƒ­ã‚°ã‚’è¡¨ç¤º
    st.markdown(f"```markdown\n{chat_log}\n```")

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›
    with st.form(key="chat_form", clear_on_submit=True):
        user_input = st.text_area("ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„:", key="input", height=100)
        submit_button = st.form_submit_button(label="é€ä¿¡")

    if submit_button and user_input:
        with st.spinner("è€ƒãˆä¸­..."):
            ai_response = chat_with_ai(user_input, model_instance, temperature)

        # ç”»é¢ã‚’æ›´æ–°ã—ã¦ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã‚’åæ˜ 
        st.rerun()  # ã“ã“ã‚’ä¿®æ­£ï¼


                  
# ğŸ”¹ **ãƒ¡ã‚¤ãƒ³é–¢æ•°**
def main():

    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®åˆæœŸåŒ–
    model_instance, page, temperature = init_sidebar()

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    project_data = load_project_data(page)

    # ãƒšãƒ¼ã‚¸ã®è¡¨ç¤ºå‡¦ç†
    if page == "Home":
        st.header("ğŸ  Home - ALTAM SOFTWARE OF LLM")
        st.write("Welcome to ALTAMGPT! ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚’ã‚µã‚¤ãƒ‰ãƒãƒ¼ã§é¸æŠã—ã¦ãã ã•ã„ã€‚")
        return

    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ˜ç¤º
    st.header(f"ğŸ“‚ {page}")
    st.write(f"ã“ã®ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã§ã¯ **{project_data}** ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

     # CSSã‚’é©ç”¨ï¼ˆèƒŒæ™¯è‰²å¤‰æ›´ & ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ‡ã‚¶ã‚¤ãƒ³ï¼‰**
    st.markdown(
    """
    <style>

     /* ğŸ”¥ ãƒ˜ãƒƒãƒ€ãƒ¼ï¼ˆStreamlit ãƒ„ãƒ¼ãƒ«ãƒãƒ¼ï¼‰ã‚’éè¡¨ç¤º */
    header, [data-testid="stToolbar"], [data-testid="stHeader"] {
        display: none !important;
        visibility: hidden !important;
        height: 0px !important;
    }

    /* ğŸ“ ãƒ•ãƒƒã‚¿ãƒ¼ã‚’éè¡¨ç¤º */
    footer, [data-testid="stFooter"], .st-emotion-cache-1wmy9hl {
        display: none !important;
        visibility: hidden !important;
        height: 0px !important;
    }

    /* ğŸ“Œ ã‚¹ãƒãƒ›ç”»é¢ã§ã®ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆèª¿æ•´ */
    @media (max-width: 768px) {
        header, footer, [data-testid="stToolbar"], [data-testid="stHeader"], [data-testid="stFooter"], .st-emotion-cache-1wmy9hl {
            display: none !important;
            visibility: hidden !important;
            height: 0px !important;
        }
    }
     
    /* ğŸŒŸ å…¨ä½“ã®èƒŒæ™¯ */
    body {
        background-color: #f4f7f9; /* è½ã¡ç€ã„ãŸãƒ–ãƒ«ãƒ¼ã‚°ãƒ¬ãƒ¼ */
        color: #333; /* æ–‡å­—ã‚’ãƒ€ãƒ¼ã‚¯ã‚°ãƒ¬ãƒ¼ */
        font-family: 'Arial', sans-serif;
    }

    /* ğŸŸ¦ ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ãƒ‡ã‚¶ã‚¤ãƒ³ */
    [data-testid="stSidebar"] {
        background-color: #1e1e2f !important;  /* æ¿ƒã„ãƒã‚¤ãƒ“ãƒ¼ãƒ–ãƒ«ãƒ¼ */
        color: white !important; /* ãƒ†ã‚­ã‚¹ãƒˆã‚’ç™½ã« */
    }

    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼å†…ã®ãƒœã‚¿ãƒ³ãƒ‡ã‚¶ã‚¤ãƒ³ */
    [data-testid="stSidebar"] button {
        background-color: #4a4a7d !important;  /* ãƒã‚¤ãƒ“ãƒ¼ãƒ–ãƒ«ãƒ¼ */
        color: white !important;  
        border: 1px solid #6b6b9d !important;
        transition: background-color 0.3s ease;
    }

    /* ãƒ›ãƒãƒ¼æ™‚ã®ãƒœã‚¿ãƒ³ã‚«ãƒ©ãƒ¼å¤‰æ›´ */
    [data-testid="stSidebar"] button:hover {
        background-color: #5a5a8d !important; 
    }

    /* ğŸ”¥ å…¥åŠ›ã‚¨ãƒªã‚¢ã®ãƒ‡ã‚¶ã‚¤ãƒ³å¤‰æ›´ */
    textarea {
        background-color: #ffffff !important;
        border: 2px solid #6b6b9d !important;
        border-radius: 8px;
        color: #333 !important;
        padding: 10px;
        font-size: 14px;
    }

    /* ã™ã¹ã¦ã®ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã‚’ã‚°ãƒ¬ãƒ¼ */
    [data-testid="stSidebar"] label {
        color: gray !important;
        font-weight: normal;
    }

    /* é¸æŠã•ã‚ŒãŸãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ©ãƒ™ãƒ«ã‚’ç™½ãã™ã‚‹ */
    [data-testid="stSidebar"] input:checked + div {
        color: white !important;
        font-weight: bold;
    }


    /* ğŸ’¬ ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®ãƒ‡ã‚¶ã‚¤ãƒ³ */
    .chat-container {
        max-height: 400px;
        overflow-y: auto;
        padding: 10px;
        background-color: #ffffff;
        border: 1px solid #ddd;
        border-radius: 8px;
    }

    /* ğŸ¨ ãƒãƒ£ãƒƒãƒˆå±¥æ­´å†…ã®å„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .chat-message {
        margin-bottom: 10px;
        padding: 10px;
        border-radius: 8px;
        font-size: 14px;
    }

    /* ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .user-message {
        background-color: #cce5ff;
        border-left: 5px solid #007bff;
    }

    /* AI ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ */
    .ai-message {
        background-color: #e6e6e6;
        border-left: 5px solid #6c757d;
    }

    /* ğŸ”˜ ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã®ãƒ‡ã‚¶ã‚¤ãƒ³ */
    [data-testid="stSidebar"] .stSlider {
        color: white !important;
    }

    /* ğŸ“Œ ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã®ãƒ‡ã‚¶ã‚¤ãƒ³ */
    [data-testid="stSidebar"] label {
        color: white !important;
        font-weight: bold;
    }

    /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã‚¿ã‚¤ãƒˆãƒ«ã‚’ç™½ãã™ã‚‹ */
    [data-testid="stSidebar"] h1 {
        color: white !important;
    }

    /* ğŸ“± ãƒ¬ã‚¹ãƒãƒ³ã‚·ãƒ–ãƒ‡ã‚¶ã‚¤ãƒ³ */
    @media (max-width: 768px) {
        body {
            font-size: 14px;
        }
        .chat-container {
            max-height: 300px;
        }
    }
    </style>
    """,
    unsafe_allow_html=True
)
        
    # ãƒãƒ£ãƒƒãƒˆã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã‚’è¡¨ç¤º
    chat_interface(model_instance, temperature)

if __name__ == '__main__':
    main()
